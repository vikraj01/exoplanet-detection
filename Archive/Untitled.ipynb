{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f49f7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_22396\\774550011.py:6: DeprecationWarning: Please use `uniform_filter1d` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import uniform_filter1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Applying Fourier...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 625. GiB for an array with shape (5124, 16381428) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 131\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28minput\u001b[39m()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Process dataset - choose which should be used\u001b[39;00m\n\u001b[0;32m     48\u001b[0m LFP \u001b[38;5;241m=\u001b[39m LightFluxProcessor(\n\u001b[0;32m     49\u001b[0m     fourier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,             \n\u001b[0;32m     51\u001b[0m     gaussian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,             \n\u001b[0;32m     52\u001b[0m     standardize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)      \n\u001b[1;32m---> 53\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mLFP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#Normalization - gives better recall but worse precision\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# X_train = ((X_train - np.mean(X_train, axis=1).reshape(-1,1)) / np.std(X_train, axis=1).reshape(-1,1))\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# X_test = ((X_test - np.mean(X_test, axis=1).reshape(-1,1)) / np.std(X_test, axis=1).reshape(-1,1))\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#TRAINING AND EVALUATING THE SVC\u001b[39;00m\n\u001b[0;32m     61\u001b[0m c_w \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m#Directory for trying out different class weights\u001b[39;00m\n\u001b[0;32m     62\u001b[0m       \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1\u001b[39m}      \u001b[38;5;66;03m#Change to kernel=c_w to use\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36mLightFluxProcessor.process\u001b[1;34m(self, X, Xd)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfourier:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying Fourier...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, arr\u001b[38;5;241m=\u001b[39mX) \n\u001b[0;32m     28\u001b[0m     Xd\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfft(Xd, n\u001b[38;5;241m=\u001b[39mXd\u001b[38;5;241m.\u001b[39msize)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, arr\u001b[38;5;241m=\u001b[39mXd)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Keep first half of data as it is symmetrical after previous steps\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\exoplanet\\env\\lib\\site-packages\\numpy\\fft\\_pocketfft.py:215\u001b[0m, in \u001b[0;36mfft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    213\u001b[0m     n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m    214\u001b[0m inv_norm \u001b[38;5;241m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[1;32m--> 215\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_fft\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\Desktop\\exoplanet\\env\\lib\\site-packages\\numpy\\fft\\_pocketfft.py:65\u001b[0m, in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[0;32m     63\u001b[0m index[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, s[axis])\n\u001b[0;32m     64\u001b[0m s[axis] \u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m---> 65\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m z[\u001b[38;5;28mtuple\u001b[39m(index)] \u001b[38;5;241m=\u001b[39m a\n\u001b[0;32m     67\u001b[0m a \u001b[38;5;241m=\u001b[39m z\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 625. GiB for an array with shape (5124, 16381428) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage, fft, integrate\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score,\\\n",
    "                recall_score, confusion_matrix, fbeta_score, auc,\\\n",
    "                  precision_recall_curve, average_precision_score\n",
    "from inspect import signature\n",
    "# Just disables a warning, doesn't enable AVX/FMA\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def main():\n",
    "    trainSetPath = \"Data/exoTrain.csv\"  # Loads datasets, requires a folder named \"datasets\"\n",
    "    testSetPath = \"Data/exoTest.csv\"    # containing the data files in your current folder\n",
    "    print(\"Loading datasets...\")\n",
    "    df_train = pd.read_csv(trainSetPath, encoding = \"ISO-8859-1\")\n",
    "    df_test = pd.read_csv(testSetPath, encoding = \"ISO-8859-1\")\n",
    "\n",
    "    # Generate X and Y dataframe set\n",
    "    df_train_x = df_train.drop('LABEL', axis=1) \n",
    "    df_test_x = df_test.drop('LABEL', axis=1)\n",
    "    df_train_y = df_train.LABEL\n",
    "    df_test_y = df_test.LABEL\n",
    "    \n",
    "    X_train = np.array(df_train_x)    #\n",
    "    Y_train = np.array(df_train_y)    # The raw input/output data for\n",
    "    X_test= np.array(df_test_x)     # both train and test sets as np.arrays\n",
    "    Y_test= np.array(df_test_y)     #\n",
    "\n",
    "    #Adding mirrored series\n",
    "    extra = np.flip(X_train[0:37,:], axis=-1)\n",
    "    extraY = Y_train[0:37]\n",
    "    X_train = np.append(X_train,extra, axis=0)\n",
    "    Y_train = np.append(Y_train,extraY,axis=0) #Kan vara bra att lägga till fler exempel för test-setet också\n",
    "    dextra = np.flip(X_test[0:5,:], axis=-1)\n",
    "    dextraY = Y_test[0:5]\n",
    "    X_test = np.append(X_test, dextra, axis=0)\n",
    "    Y_test = np.append(Y_test,dextraY,axis=0)\n",
    "\n",
    "    Y_train=Y_train-1       #\n",
    "    Y_test=Y_test-1     # To get postives to 1 and negatives to 0\n",
    "\n",
    "    # Process dataset - choose which should be used\n",
    "    LFP = LightFluxProcessor(\n",
    "        fourier=True,\n",
    "        normalize=False,             \n",
    "        gaussian=False,             \n",
    "        standardize=False)      \n",
    "    X_train, X_test = LFP.process(X_train, X_test)\n",
    "\n",
    "    #Normalization - gives better recall but worse precision\n",
    "    # X_train = ((X_train - np.mean(X_train, axis=1).reshape(-1,1)) / np.std(X_train, axis=1).reshape(-1,1))\n",
    "    # X_test = ((X_test - np.mean(X_test, axis=1).reshape(-1,1)) / np.std(X_test, axis=1).reshape(-1,1))\n",
    "\n",
    "\n",
    "    #TRAINING AND EVALUATING THE SVC\n",
    "    c_w = {0: 1,  #Directory for trying out different class weights\n",
    "          1: 1}      #Change to kernel=c_w to use\n",
    "\n",
    "    model=SVC(kernel='linear', gamma='scale', class_weight='balanced', probability=True, max_iter=10000)   # Choosing model\n",
    "    print(\"Training...\")\n",
    "    model.fit(X_train, Y_train)            # Choose which data to train on\n",
    "    print(\"Finished training!\")\n",
    "    print('')\n",
    "    print(\"Making predictions..\")\n",
    "    train_outputs=model.predict(X_train)     # Making predictions\n",
    "    test_outputs =model.predict(X_test)    #\n",
    "\n",
    "    train_prob = model.predict_proba(X_train)[:,1]\n",
    "    test_prob = model.predict_proba(X_test)[:,1]\n",
    "    print(\"Finished predictions!\")\n",
    "\n",
    "    #region Various metrics for performance\n",
    "    ap_train = average_precision_score(Y_train, train_prob)\n",
    "    ap_test = average_precision_score(Y_test, test_prob)\n",
    "\n",
    "    #Precision recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(Y_train,train_prob) #train\n",
    "    precision_d, recall_d, thresholds_d = precision_recall_curve(Y_test,test_prob) #test\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                if 'step' in signature(plt.fill_between).parameters\n",
    "                else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "            where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('SVM: Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "    accuracy_train=accuracy_score(Y_train,train_outputs)\n",
    "    accuracy_test=accuracy_score(Y_test,test_outputs)\n",
    "    precision_train=precision_score(Y_train,train_outputs)\n",
    "    precision_test=precision_score(Y_test,test_outputs)\n",
    "    recall_train = recall_score(Y_train, train_outputs)\n",
    "    recall_test = recall_score(Y_test,test_outputs)\n",
    "    f1_train = f1_score(Y_train,train_outputs)\n",
    "    f1_test = f1_score(Y_test,test_outputs)\n",
    "\n",
    "    print(\"AUC training set: %.3f\" %ap_train )\n",
    "    print(\"AUC test set: %.3f\" %ap_test )\n",
    "    print(\"Accuracy training set: %.3f\" %accuracy_train)\n",
    "    print(\"Accuracy test set: %.3f\" %accuracy_test)\n",
    "    print(\"Precision training set: %.3f\" %precision_train)\n",
    "    print(\"Precision test set: %.3f\" %precision_test)\n",
    "    print(\"Recall training set: %.3f\" %recall_train)\n",
    "    print(\"Recall test set: %.3f\" %recall_test)\n",
    "    print(\"F1 score training set: %.3f\" %f1_train)\n",
    "    print(\"F1 score test set: %.3f\" %f1_test)\n",
    "    print(' ')\n",
    "    confM=confusion_matrix(Y_train,train_outputs)\n",
    "    print(\"Confusion Matrix - Train Set\")\n",
    "    print(confM)\n",
    "\n",
    "    confMd=confusion_matrix(Y_test,test_outputs)\n",
    "    print(\"Confusion Matrix - Test Set\")\n",
    "    print(confMd) \n",
    "    #endregion\n",
    "\n",
    "    input()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5798e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing inspired by Gabriel Garca. Only fourier used in final version\n",
    "#https://github.com/gabrielgarza/exoplanet-deep-learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage, fft\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "from scipy.signal import butter\n",
    "\n",
    "class LightFluxProcessor:\n",
    "\n",
    "    def __init__(self, fourier=True, normalize=True, gaussian=True, standardize=True):\n",
    "        self.fourier = fourier\n",
    "        self.normalize = normalize\n",
    "        self.gaussian = gaussian\n",
    "        self.standardize = standardize\n",
    "\n",
    "##FUNDERA PÅ ORDNINGEN PÅ PROCESS-GREJSET\n",
    "    def process(self, X, Xd):\n",
    "        # Normalize\n",
    "        if self.normalize:\n",
    "            print(\"Normalizing...\")\n",
    "            X = normalize(X)\n",
    "            Xd = normalize(Xd)\n",
    "\n",
    "        if self.fourier:\n",
    "            print(\"Applying Fourier...\")\n",
    "            X = np.apply_along_axis(np.abs(np.fft.fft(X, n=X.size)), axis=1, arr=X) \n",
    "            Xd= np.apply_along_axis(np.abs(np.fft.fft(Xd, n=Xd.size)), axis=1, arr=Xd)\n",
    "\n",
    "            # Keep first half of data as it is symmetrical after previous steps\n",
    "            X = X[:,:(X.shape[1]//2)]\n",
    "            Xd= Xd[:,:(Xd.shape[1]//2)]\n",
    "\n",
    "        # Gaussian filter to smooth out data\n",
    "        if self.gaussian:\n",
    "            print(\"Applying Gaussian Filter...\")\n",
    "            X = ndimage.filters.gaussian_filter1d(X, sigma=10) #--_filter1d eller inte?\n",
    "            Xd = ndimage.filters.gaussian_filter1d(Xd, sigma=10)\n",
    "\n",
    "        if self.standardize:\n",
    "            # Standardize X data\n",
    "            print(\"Standardizing...\")\n",
    "            std_scaler = StandardScaler()\n",
    "            X = std_scaler.fit_transform(X)\n",
    "            Xd = std_scaler.transform(Xd)\n",
    "        \n",
    "                # Apply fourier transform\n",
    "        \n",
    "\n",
    "        print(\"Finished Processing!\")\n",
    "        return X, Xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd79bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
