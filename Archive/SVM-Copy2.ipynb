{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fae75f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from scipy import ndimage, fft\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c7bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFluxProcessor:\n",
    "\n",
    "    def __init__(self, fourier=True, normalize=True, gaussian=True, standardize=True):\n",
    "        self.fourier = fourier\n",
    "        self.normalize = normalize\n",
    "        self.gaussian = gaussian\n",
    "        self.standardize = standardize\n",
    "\n",
    "    def fourier_transform(self, X):\n",
    "        return np.abs(np.fft.fft(X, n=X.size))\n",
    "\n",
    "    def process(self, df_train_x, df_dev_x):\n",
    "        if self.fourier:\n",
    "            print(\"Applying Fourier...\")\n",
    "            df_train_x = np.apply_along_axis(self.fourier_transform, axis=1, arr=df_train_x)\n",
    "            df_dev_x = np.apply_along_axis(self.fourier_transform, axis=1, arr=df_dev_x)\n",
    "\n",
    "            df_train_x = df_train_x[:, :(df_train_x.shape[1] // 2)]\n",
    "            df_dev_x = df_dev_x[:, :(df_dev_x.shape[1] // 2)]\n",
    "\n",
    "        if self.normalize:\n",
    "            print(\"Normalizing...\")\n",
    "            df_train_x = normalize(df_train_x)\n",
    "            df_dev_x = normalize(df_dev_x)\n",
    "\n",
    "        if self.gaussian:\n",
    "            print(\"Applying Gaussian Filter...\")\n",
    "            df_train_x = ndimage.filters.gaussian_filter(df_train_x, sigma=10)\n",
    "            df_dev_x = ndimage.filters.gaussian_filter(df_dev_x, sigma=10)\n",
    "\n",
    "        if self.standardize:\n",
    "            print(\"Standardizing...\")\n",
    "            std_scaler = StandardScaler()\n",
    "            df_train_x = std_scaler.fit_transform(df_train_x)\n",
    "            df_dev_x = std_scaler.transform(df_dev_x)\n",
    "\n",
    "        print(\"Finished Processing!\")\n",
    "        return df_train_x, df_dev_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e752d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_X_Y_from_df(df):\n",
    "    df = shuffle(df)\n",
    "    df_X = df.drop(['LABEL'], axis=1)\n",
    "    X = np.array(df_X)\n",
    "    Y_raw = np.array(df['LABEL']).reshape((len(df['LABEL']),1))\n",
    "    Y = Y_raw == 2\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce1bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loaded datasets!\n",
      "Applying Fourier...\n",
      "Finished Processing!\n",
      "Describing Datasets...\n",
      "X_train.shape:  (5087, 1598)\n",
      "Y_train.shape:  (5087, 1)\n",
      "X_dev.shape:  (570, 1598)\n",
      "Y_dev.shape:  (570, 1)\n",
      "n_x:  1598\n",
      "num_examples:  5087\n",
      "n_y:  1\n",
      "Hyperparameter tuning in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Grid Search Progress:   0%|                                                            | 0/72 [00:00<?, ?combination/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_dataset_path = \"Data/exoTrain.csv\"\n",
    "    dev_dataset_path = \"Data/exoTest.csv\"\n",
    "\n",
    "    print(\"Loading datasets...\")\n",
    "    df_train = pd.read_csv(train_dataset_path, encoding = \"ISO-8859-1\")\n",
    "    df_dev = pd.read_csv(dev_dataset_path, encoding = \"ISO-8859-1\")\n",
    "    print(\"Loaded datasets!\")\n",
    "\n",
    "    df_train_x = df_train.drop('LABEL', axis=1)\n",
    "    df_dev_x = df_dev.drop('LABEL', axis=1)\n",
    "    df_train_y = df_train.LABEL\n",
    "    df_dev_y = df_dev.LABEL\n",
    "    LFP = LightFluxProcessor(\n",
    "        fourier=True,\n",
    "        normalize=False,\n",
    "        gaussian=False,\n",
    "        standardize=False)\n",
    "    df_train_x, df_dev_x = LFP.process(df_train_x, df_dev_x)\n",
    "\n",
    "    df_train_processed = pd.DataFrame(df_train_x).join(pd.DataFrame(df_train_y))\n",
    "    df_dev_processed = pd.DataFrame(df_dev_x).join(pd.DataFrame(df_dev_y))\n",
    "\n",
    "    X_train, Y_train = np_X_Y_from_df(df_train_processed)\n",
    "    X_dev, Y_dev = np_X_Y_from_df(df_dev_processed)\n",
    "    \n",
    "    print(\"Describing Datasets...\")\n",
    "    (num_examples, n_x) = X_train.shape\n",
    "    n_y = Y_train.shape[1] \n",
    "    print(\"X_train.shape: \", X_train.shape)\n",
    "    print(\"Y_train.shape: \", Y_train.shape)\n",
    "    print(\"X_dev.shape: \", X_dev.shape)\n",
    "    print(\"Y_dev.shape: \", Y_dev.shape)\n",
    "    print(\"n_x: \", n_x)\n",
    "    print(\"num_examples: \", num_examples)\n",
    "    print(\"n_y: \", n_y)\n",
    "    \n",
    "    ## \n",
    "    # Perform hyperparameter tuning\n",
    "    best_params, model = perform_grid_search(X_train, Y_train)\n",
    "\n",
    "    # Train the best model\n",
    "    print(\"Training with the best parameters...\", best_params)\n",
    "    \n",
    "\n",
    "    X_train_sm, Y_train_sm = X_train, Y_train\n",
    "\n",
    "    # Train\n",
    "    print(\"Training...\")\n",
    "    model.fit(X_train_sm, Y_train_sm)\n",
    "\n",
    "    train_outputs = model.predict(X_train_sm)\n",
    "    dev_outputs = model.predict(X_dev)\n",
    "    print(\"Finished Training!\")\n",
    "    \n",
    "\n",
    "    train_prob = model.decision_function(X_train)  \n",
    "    dev_prob = model.decision_function(X_dev)\n",
    "\n",
    "\n",
    "    train_outputs = (train_prob > 0).astype(int)\n",
    "    dev_outputs = (dev_prob > 0).astype(int)\n",
    "\n",
    "    accuracy_train = accuracy_score(Y_train_sm, train_outputs)\n",
    "    accuracy_dev = accuracy_score(Y_dev, dev_outputs)\n",
    "    precision_train = precision_score(Y_train_sm, train_outputs)\n",
    "    precision_dev = precision_score(Y_dev, dev_outputs)\n",
    "    recall_train = recall_score(Y_train_sm, train_outputs)\n",
    "    recall_dev = recall_score(Y_dev, dev_outputs)\n",
    "    confusion_matrix_train = confusion_matrix(Y_train_sm, train_outputs)\n",
    "    confusion_matrix_dev = confusion_matrix(Y_dev, dev_outputs)\n",
    "    classification_report_train = classification_report(Y_train_sm, train_outputs)\n",
    "    classification_report_dev = classification_report(Y_dev, dev_outputs)\n",
    "\n",
    "    # Calculate AUC scores\n",
    "    ap_train = average_precision_score(Y_train_sm, train_prob)\n",
    "    ap_dev = average_precision_score(Y_dev, dev_prob)\n",
    "\n",
    "    # Display metrics\n",
    "    print(\"AUC training set: %.3f\" % ap_train)\n",
    "    print(\"AUC dev set: %.3f\" % ap_dev)\n",
    "    print(\"Accuracy training set: %.3f\" % accuracy_train)\n",
    "    print(\"Accuracy dev set: %.3f\" % accuracy_dev)\n",
    "    print(\"Precision training set: %.3f\" % precision_train)\n",
    "    print(\"Precision dev set: %.3f\" % precision_dev)\n",
    "    print(\"Recall training set: %.3f\" % recall_train)\n",
    "    print(\"Recall dev set: %.3f\" % recall_dev)\n",
    "    print(\" \")\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, thresholds = precision_recall_curve(Y_train_sm, train_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='b', alpha=0.8)\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', step='post')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion matrices\n",
    "    print(\"Confusion Matrix - Train Set\")\n",
    "    print(confusion_matrix_train)\n",
    "    print(\"Confusion Matrix - Dev Set\")\n",
    "    print(confusion_matrix_dev)\n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1204b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "def perform_grid_search(X_train, Y_train):\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto', 0.1],\n",
    "        'shrinking': [True, False],\n",
    "        'max_iter': [1000, 2000],\n",
    "    }\n",
    "\n",
    "    svc = SVC()\n",
    "    grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    \n",
    "    print(\"Hyperparameter tuning in progress...\")\n",
    "\n",
    "    try:\n",
    "        with tqdm(total=len(param_grid['C']) * len(param_grid['kernel']) * len(param_grid['gamma']) *\n",
    "                  len(param_grid['shrinking']) * len(param_grid['max_iter']),\n",
    "                  desc=\"Grid Search Progress\", unit=\"combination\") as progress_bar:\n",
    "            grid_search.fit(X_train, Y_train)\n",
    "            progress_bar.update(1)  # Manually update the progress bar as GridSearchCV doesn't provide progress updates\n",
    "        print(\"\\nGrid search complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during grid search: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "    # Save the best model to a binary file using joblib\n",
    "    best_model = grid_search.best_estimator_\n",
    "    joblib.dump(best_model, 'best_model.joblib')\n",
    "\n",
    "    # Save the best parameters to a JSON file\n",
    "    best_params = grid_search.best_params_\n",
    "    with open('best_params.json', 'w') as json_file:\n",
    "        json.dump(best_params, json_file)\n",
    "\n",
    "    # Extract results into a DataFrame and print it\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    print(\"\\nGrid search results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results_df.to_csv('grid_search_results.csv', index=False)\n",
    "\n",
    "    return 'best_model.joblib', 'best_params.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c26de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
